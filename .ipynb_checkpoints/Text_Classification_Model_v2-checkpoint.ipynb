{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification on Song Lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II : Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims at building a text classification model on song lyrics. The task is to predict the artist from song text. We will focus on two artist from the \"Heavy Metal\" genre: Ronnie James Dio (Dio) and Ozzy Osbourne (Ozzy). Training such a model requires first of all that we collect our own lyrics dataset. This feat has already been achieved in Part I of the project by making use of the website:  http://www.darklyrics.com. \n",
    "\n",
    "In Part II, we will train various models on the dataset we collected. We will select the best model hyperparameter tuning with k-fold cross validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting libraries\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set() # set seaborn as default style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Rakibur\n",
      "[nltk_data]     Rahman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# language pre-processing libraries\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning libraries\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other libraries\n",
    "import time\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 User Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text pre-processing function\n",
    "\n",
    "def text_preprocess(text):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns cleaned text in as string\n",
    "    \"\"\"\n",
    "    # removing punctuation\n",
    "    no_punc = [char for char in text if char not in string.punctuation]\n",
    "\n",
    "    # rejoining the characters to form the string\n",
    "    no_punc = ''.join(no_punc)\n",
    "    \n",
    "    # removing stopwords\n",
    "    clean = [word for word in no_punc.split() if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    # rejoining characters to form string\n",
    "    clean = ' '.join(clean)\n",
    "    \n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for grid serach serach of best hyperparameters\n",
    "\n",
    "def model_fit(clf_name,X_,y_,cv_):\n",
    "    '''This function finds best estimator for a given classifier'''\n",
    "   \n",
    "    grid = GridSearchCV(clf[clf_name], param_grid=hp[clf_name], return_train_score=True,\n",
    "                        scoring='accuracy', n_jobs=-1, cv=cv_)\n",
    "\n",
    "    pipeline = Pipeline([('c_vec',CountVectorizer()), ('tfidf',TfidfTransformer()), ('grid',grid)])\n",
    "#     pipeline = Pipeline([('c_vec',CountVectorizer()), ('grid',grid)])\n",
    "    \n",
    "    ti = time.time()\n",
    "    \n",
    "    pipeline.fit(X_,y_) # training the model\n",
    "    \n",
    "    tf = time.time()\n",
    "    min_,sec_ = [int((tf-ti)/60),int((tf-ti)%60)]\n",
    "    print(f'hyperparameter tuning took: {min_} min {sec_} sec')\n",
    "    \n",
    "    best_params = grid.best_params_\n",
    "    print(f'best hyperparameters: {best_params}')\n",
    "    \n",
    "    best_score = round(grid.best_score_,3)\n",
    "    print(f'best validation score: {best_score}')\n",
    "    \n",
    "    best_pipeline = Pipeline([('c_vec',CountVectorizer()),('tfidf',TfidfTransformer()),('grid',grid.best_estimator_)])\n",
    "    return best_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for voting classifier\n",
    "\n",
    "def voting_(voter_list,vote_type,models):\n",
    "    '''This function creates a voting classifier of a number of estimators,\n",
    "    which is subsequently trained and tested'''\n",
    "    \n",
    "    # creating voting classifier\n",
    "    estimator_list = []\n",
    "    for clf_name in voter_list:\n",
    "        estimator_list.append((clf_name,models[clf_name]))\n",
    "    voting_clf = VotingClassifier(estimators=estimator_list,voting=vote_type)\n",
    "    \n",
    "    # training the voting classifier\n",
    "    voting_model = voting_clf.fit(X,y)\n",
    "    \n",
    "    return voting_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from file\n",
    "df = pd.read_csv('songlines.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe Quick Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's the same old song</td>\n",
       "      <td>Dio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you gotta be somewhere at sometime</td>\n",
       "      <td>Dio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and they'll never let you fly</td>\n",
       "      <td>Dio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's like broken glass</td>\n",
       "      <td>Dio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you get cut before you see it</td>\n",
       "      <td>Dio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 line artist\n",
       "0              It's the same old song    Dio\n",
       "1  you gotta be somewhere at sometime    Dio\n",
       "2       and they'll never let you fly    Dio\n",
       "3              It's like broken glass    Dio\n",
       "4       you get cut before you see it    Dio"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9006</th>\n",
       "      <td>And I don't walk on water (oh no)</td>\n",
       "      <td>Ozzy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9007</th>\n",
       "      <td>I don't walk on water (oh no)</td>\n",
       "      <td>Ozzy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9008</th>\n",
       "      <td>My dromedary dreams as wet as oceans</td>\n",
       "      <td>Ozzy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9009</th>\n",
       "      <td>With sand dunes bearing seeds she set in motion</td>\n",
       "      <td>Ozzy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9010</th>\n",
       "      <td>My dromedary dreams my dromedary dreams my dro...</td>\n",
       "      <td>Ozzy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   line artist\n",
       "9006                  And I don't walk on water (oh no)   Ozzy\n",
       "9007                      I don't walk on water (oh no)   Ozzy\n",
       "9008              My dromedary dreams as wet as oceans    Ozzy\n",
       "9009   With sand dunes bearing seeds she set in motion    Ozzy\n",
       "9010  My dromedary dreams my dromedary dreams my dro...   Ozzy"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check tail\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9011 entries, 0 to 9010\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   line    9011 non-null   object\n",
      " 1   artist  9011 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 140.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# some information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Target Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ozzy    0.599157\n",
       "Dio     0.400843\n",
       "Name: artist, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['artist'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: Dataset is no highly imbalanced, but not very balanced either. ROC or f1 score might be a better measure than accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0 min 19 sec\n"
     ]
    }
   ],
   "source": [
    "# create pre-processed song-line column\n",
    "\n",
    "ti = time.time()\n",
    "\n",
    "df['line_pp'] = df['line'].apply(text_preprocess) # pre-processing step\n",
    "\n",
    "tf = time.time()\n",
    "min_,sec_ = [int((tf-ti)/60),int((tf-ti)%60)]\n",
    "\n",
    "print(f'elapsed time: {min_} min {sec_} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9011 entries, 0 to 9010\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   line     9011 non-null   object\n",
      " 1   artist   9011 non-null   object\n",
      " 2   line_pp  9011 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 211.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# check dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Feature/Target Variable Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature: text\n",
    "X = df['line_pp']\n",
    "\n",
    "# label: artist name\n",
    "y = df['artist'].map({'Dio':1,'Ozzy':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature data: (9011,)\n",
      "target data : (9011,)\n"
     ]
    }
   ],
   "source": [
    "print(f'feature data: {X.shape}')\n",
    "print(f'target data : {y.shape}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Baseline Model\n",
    "\n",
    "All labels belong to the majority class 0 (all lines belong to Ozzy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model predictions\n",
    "yb_pred = np.zeros(df['artist'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.599, AUC: 0.5, f1_score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# baseline scores\n",
    "acc_b = round(accuracy_score(y,yb_pred),3)\n",
    "auc_b = round(roc_auc_score(y,yb_pred),3)\n",
    "f1_b = round(f1_score(y,yb_pred),3)\n",
    "print(f'accuracy: {acc_b}, AUC: {auc_b}, f1_score: {f1_b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: One must have accuracy > 0.60 and AUC > 0.50 in order for a model to be good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we do hyperparameter tuning with cross validation of various classfiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect three classifiers: PassiveAggressive, \n",
    "clf = {'LRC': LogisticRegression(),\n",
    "       'PAC': PassiveAggressiveClassifier(),\n",
    "       'NBC': MultinomialNB(),\n",
    "       'DTC': DecisionTreeClassifier(),\n",
    "       'RFC': RandomForestClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter grid\n",
    "hp = {'LRC': dict(C=10.**np.arange(-3,3), penalty=['l2','none']),\n",
    "      'PAC': dict(C = 10.**np.arange(-3, 3),max_iter = list(range(1_000,10_100,100))),\n",
    "      'NBC': dict(alpha=[0.5,1.0,1.5,2.0,2.5], fit_prior=[True,False], class_prior=[None]), \n",
    "      'DTC': dict(criterion=['gini','entropy'], min_samples_leaf=list(range(1,10)), max_depth=list(range(2,14,2))),\n",
    "      'RFC': dict(n_estimators=[10,50,100,500,1000], max_features=['auto','sqrt','log2'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparameter tuning took: 0 min 12 sec\n",
      "best hyperparameters: {'C': 10.0, 'penalty': 'l2'}\n",
      "best validation score: 0.712\n"
     ]
    }
   ],
   "source": [
    "LRC_model = model_fit('LRC',X,y,cv_=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2 Passive-Aggressive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparameter tuning took: 1 min 6 sec\n",
      "best hyperparameters: {'C': 0.01, 'max_iter': 3800}\n",
      "best validation score: 0.71\n"
     ]
    }
   ],
   "source": [
    "PAC_model = model_fit('PAC',X,y,cv_=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.3 Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparameter tuning took: 0 min 0 sec\n",
      "best hyperparameters: {'alpha': 1.0, 'class_prior': None, 'fit_prior': True}\n",
      "best validation score: 0.7\n"
     ]
    }
   ],
   "source": [
    "NBC_model = model_fit('NBC',X,y,cv_=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.4 Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparameter tuning took: 0 min 15 sec\n",
      "best hyperparameters: {'criterion': 'gini', 'max_depth': 12, 'min_samples_leaf': 1}\n",
      "best validation score: 0.636\n"
     ]
    }
   ],
   "source": [
    "DTC_model = model_fit('DTC',X,y,cv_=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.5 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparameter tuning took: 24 min 35 sec\n",
      "best hyperparameters: {'max_features': 'log2', 'n_estimators': 500}\n",
      "best validation score: 0.729\n"
     ]
    }
   ],
   "source": [
    "RFC_model = model_fit('RFC',X,y,cv_=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Model Training (Best Hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logictic Regression\n",
    "LRC_best = LRC_model.fit(X,y)\n",
    "\n",
    "# Passive Aggressive Classifier\n",
    "PAC_best = PAC_model.fit(X,y)\n",
    "\n",
    "# Naive Bayes Classifier\n",
    "NBC_best = NBC_model.fit(X,y)\n",
    "\n",
    "# Decision Tree Classifier\n",
    "DTC_best = DTC_model.fit(X,y)\n",
    "\n",
    "# Random Forest Classifier\n",
    "RFC_best = RFC_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logictic Regression\n",
    "joblib.dump(LRC_best, 'LRC_best_v2.pkl')\n",
    "\n",
    "# Passive Aggressive Classifier\n",
    "joblib.dump(PAC_best, 'PAC_best_v2.pkl')\n",
    "\n",
    "# Naive Bayes Classifier\n",
    "joblib.dump(NBC_best, 'NBC_best_v2.pkl')\n",
    "\n",
    "# Decision Tree Classifier\n",
    "joblib.dump(DTC_best, 'DTC_best_v2.pkl')\n",
    "\n",
    "\n",
    "# Random Forest Classifier\n",
    "joblib.dump(RFC_best, 'RFC_best_v2.pkl')\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logictic Regression\n",
    "model_LRC = joblib.load('LRC_best_v2.pkl')\n",
    "\n",
    "# Passive Aggressive Classifier\n",
    "model_PAC = joblib.load('PAC_best_v2.pkl')\n",
    "\n",
    "# Naive Bayes Classifier\n",
    "model_NBC = joblib.load('NBC_best_v2.pkl')\n",
    "\n",
    "# Decision Tree Classifier\n",
    "model_DTC = joblib.load('DTC_best_v2.pkl')\n",
    "\n",
    "# Random Forest Classifier\n",
    "model_RFC = joblib.load('RFC_best_v2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:\n",
      "LRC: 0.684824\n",
      "PAC: 0.690039\n",
      "NBC: 0.690152\n",
      "DTC: 0.629341\n",
      "RFC: 0.694591\n"
     ]
    }
   ],
   "source": [
    "# cross validation score\n",
    "\n",
    "models = {'LRC':model_LRC, 'PAC':model_PAC, 'NBC':model_NBC, 'DTC':model_DTC, 'RFC':model_RFC}\n",
    "\n",
    "print('validation accuracy:')\n",
    "for model in models:\n",
    "    cross_score = cross_val_score(estimator=models[model], X=X, y=y, cv=5, scoring='accuracy')\n",
    "    avg_score = round(cross_score.mean(),6)\n",
    "    print(f'{model}: {avg_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter song line of Dio or Ozzy\n",
    "song_line = 'There is a dragon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process\n",
    "song_line_pp = text_preprocess(song_line)\n",
    "text = [song_line_pp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRC: Dio\n",
      "PAC: Dio\n",
      "NBC: Dio\n",
      "DTC: Ozzy\n",
      "RFC: Dio\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "for model in models:\n",
    "    y_pred = models[model].predict(text)[0]\n",
    "    if y_pred==1:\n",
    "        atrist_pred = 'Dio'\n",
    "    if y_pred==0:\n",
    "        atrist_pred = 'Ozzy'\n",
    "    print(f'{model}: {atrist_pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voter list: ['PAC', 'NBC', 'RFC']\n"
     ]
    }
   ],
   "source": [
    "# voter list\n",
    "voter_list = [classifier for classifier in clf]\n",
    "voter_list.remove('LRC')\n",
    "voter_list.remove('DTC')\n",
    "print(f'voter list: {voter_list}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained hard voting model\n",
    "hard_voting_model = voting_(voter_list,'hard',models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained soft voting model\n",
    "soft_voting_model = voting_(voter_list,'soft',models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:\n",
      "Hard_Voting: 0.697586\n",
      "Soft_Voting: nan\n"
     ]
    }
   ],
   "source": [
    "# cross validation score\n",
    "\n",
    "voting_models = {'Hard_Voting':hard_voting_model}\n",
    "# voting_models = {'Hard_Voting':hard_voting_model, 'Soft_Voting':soft_voting_model}\n",
    "\n",
    "print('validation accuracy:')\n",
    "for model in voting_models:\n",
    "    cross_score = cross_val_score(estimator=voting_models[model], X=X, y=y, cv=5, scoring='accuracy')\n",
    "    avg_score = round(cross_score.mean(),6)\n",
    "    print(f'{model}: {avg_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation of metrics\n",
    "\n",
    "for model in voting_models:\n",
    "    print(model)\n",
    "    y_pred = voting_models[model].predict(X)\n",
    "    \n",
    "    accuracy = round(accuracy_score(y,y_pred),3)\n",
    "    print(f'accuracy: {accuracy}')\n",
    "    \n",
    "    precision = round(precision_score(y,y_pred),3)\n",
    "    print(f'precision: {precision}')\n",
    "    \n",
    "    recall = round(recall_score(y,y_pred),3)\n",
    "    print(f'precision: {precision}')\n",
    "    \n",
    "    f1 = round(f1_score(y,y_pred),3)\n",
    "    print(f'f1_score: {f1}')\n",
    "    \n",
    "    auc = round(roc_auc_score(y,y_pred),3)\n",
    "    print(f'AUC: {auc}')\n",
    "    \n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    print('confusion_matrix:')\n",
    "    print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
